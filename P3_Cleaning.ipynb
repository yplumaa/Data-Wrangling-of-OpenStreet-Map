{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 Cleaning of the OpenStreet Map Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#P3-Cleaning-of-the-OpenStreet-Map-Data#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "import pprint\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "#File names for csv format data\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "#Schema was defined in the \"schema.py\" file\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "#Define all the regular expressions used\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "lOWER = re.compile(r'^([a-z]|_)*$')\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "postcode_re = re.compile(r'^\\d{5}(-\\d{4})?$')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "# ================================================== #\n",
    "#               Cleaning Functions                   #\n",
    "# ================================================== #\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Freeway\", \"Loop\", \"Park\",\"Way\",\"Plaza\",\"Speedway\"]\n",
    "\n",
    "mapping_streetType= { \n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Fwy\":\"Freeway\",\n",
    "             'Plaze':\"Plaza\",\n",
    "            \"Rd\": \"Road\",\n",
    "             \"St\": \"Street\",\n",
    "             \"Stree\": \"Street\",\n",
    "             \"Ste\":\"Suite\",\n",
    "            \"Hwy\":\"Highway\",\n",
    "            \"Pkwy\":'Parkway'}\n",
    "mapping_streetName={\n",
    "            'Beechnut': 'Beechnut Street',\n",
    "            'Blossom': 'Blossom Street',\n",
    "            'Driscoll':'Driscoll Street',\n",
    "            'Durham': 'Durham Drive',\n",
    "            'San Felipe':'San Felipe Street',\n",
    "            'Graustark': 'Graustark Street',\n",
    "            'Hidalgo': 'Hidalgo Street',\n",
    "            'Hillcroft': 'Hillcroft Avenue',\n",
    "            'Larchmont': 'Larchmont Road',\n",
    "            'Maroneal': 'Maroneal Street',\n",
    "             'Richmond': 'Richmond Avenue',\n",
    "             'Riverway': 'Riverway Drive',\n",
    "             'Chimney Rock': 'Chimney Rock Road',\n",
    "            'Pine Valley': 'Pine Valley Drive',\n",
    "            'Welford': 'Welford Drive',\n",
    "            'Westheimer': 'Westheimer Road',\n",
    "             'Westhimer': 'Westheimer Road',\n",
    "            \"Meyerland Plaza, Houston, TX 77096\":\"Beechnut Street\",\n",
    "            '77027':\"Weslayan Street\",\n",
    "            'Southwest Freeway 59': 'Southwest Freeway',  \n",
    "            'Meyerland Plaza Mall': \"Beechnut Street\"        \n",
    "}\n",
    "\n",
    "mapping_postcode={'Weslayan Street': '77027',\n",
    "                  '7-':'77478'}\n",
    "def get_key_tagType(key,default):\n",
    "     \"\"\"\n",
    "         Get key and tag type from key\n",
    "         Args:\n",
    "                   key (string): the unprocessed key\n",
    "                   default (string): default type of the key\n",
    "         Returns:\n",
    "                   string1: processed key\n",
    "                   string2: updated type of the key\n",
    "    \"\"\"\n",
    "    if PROBLEMCHARS.match(key):\n",
    "        return None, None\n",
    "    n=key.find(':')\n",
    "    if n==-1:\n",
    "        return default, key\n",
    "    else:\n",
    "        return key[:n],key[n+1:]\n",
    "\n",
    "def update_street(name, mapping_streetName, mapping_streetType):\n",
    "     \"\"\"\n",
    "         Update street names and types\n",
    "         Args:\n",
    "                   name (string): the unprocessed street name\n",
    "                   mapping_streetName (dictionary): chart to match some incorrect info or typo for street names\n",
    "                   mapping_streetTypes (dictionary): chart to map words with abbreviation\n",
    "         Returns:\n",
    "                   string: updated street name\n",
    "    \"\"\"\n",
    "# Initialize Return\n",
    "    corr_name=name\n",
    "# Correct idiosyncratic cases:\n",
    "    if name in mapping_streetName:\n",
    "        corr_name=mapping_streetName[name]\n",
    "#Expanding Common Abbr.\n",
    "    else: \n",
    "        words=name.split()\n",
    "        for i in range(len(words)) :\n",
    "            if words[i] in mapping_streetType:\n",
    "                words[i]=mapping_streetType[words[i]]\n",
    "        corr_name=\" \".join(words)\n",
    "    return corr_name\n",
    "\n",
    "def update_postcode(postcode, mapping_postcode):\n",
    "    \"\"\"\n",
    "         Update postal codes\n",
    "         Args:\n",
    "                   name (string): the unprocessed postal code\n",
    "                   mapping_postcode (dictionary): chart to map incorrect input postal codes with corrected ones\n",
    "         Returns:\n",
    "                   string: updated postal code\n",
    "    \"\"\"\n",
    "    corr_postcode=postcode\n",
    "    if not postcode_re.match(postcode):\n",
    "        if postcode in mapping_postcode:\n",
    "            corr_postcode=mapping_postcode[postcode]\n",
    "    return corr_postcode\n",
    "# ================================================== #\n",
    "#               Formating Data Function              #\n",
    "# ================================================== #\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for attr in node_attr_fields:\n",
    "            node_attribs[attr]=element.attrib[attr]\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            key_string=tag.attrib['k']\n",
    "            #Process tag key\n",
    "            tag_type,key=get_key_tagType(key_string,default_tag_type)\n",
    "            #Assign the variables to use in the data structure\n",
    "            node_id=node_attribs['id']\n",
    "            value=tag.attrib['v']\n",
    "            # Cleaning street names\n",
    "            if key[0:6]=='street': value=update_street(value,mapping_streetName, mapping_streetType)\n",
    "            # Cleaning post codes\n",
    "            if key[0:8]=='postcode': value=update_postcode(value,mapping_postcode)\n",
    "            # append data to node tag list\n",
    "            tags.append({'id':node_id,\n",
    "                            'key':key,\n",
    "                            'value':value,\n",
    "                            'type':tag_type})\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for attr in way_attr_fields:\n",
    "            way_attribs[attr]=element.attrib[attr]\n",
    "        i=0\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            way_nodes.append({'id':way_attribs['id'],\n",
    "                              'node_id':nd.attrib['ref'],\n",
    "                              'position':i})\n",
    "            i+=1\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            key_string=tag.attrib['k']\n",
    "            tag_type,key=get_key_tagType(key_string,default_tag_type)\n",
    "            #Assign the variables to use in the data structure\n",
    "            way_id=way_attribs['id']\n",
    "            value=tag.attrib['v']\n",
    "            # Cleaning street names\n",
    "            if key[0:6]=='street': value=update_street(value,mapping_streetName, mapping_streetType)\n",
    "            # Cleaning post codes\n",
    "            if key[0:8]=='postcode': value=update_postcode(value,mapping_postcode)\n",
    "            # append data to way tag list\n",
    "            tags.append({'id':way_id,\n",
    "                         'key':key,\n",
    "                         'value':value,\n",
    "                         'type':tag_type})\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "        codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "# Validate with sample file first, then run the larger OSM file.\n",
    "    #process_map('sample.osm', validate=True)\n",
    "    process_map('HoustonSW.osm',validate=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
